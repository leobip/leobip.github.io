<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.10.0">Jekyll</generator><link href="http://localhost:4000/feed.xml" rel="self" type="application/atom+xml" /><link href="http://localhost:4000/" rel="alternate" type="text/html" /><updated>2025-09-29T21:10:50+02:00</updated><id>http://localhost:4000/feed.xml</id><title type="html">My Personal Page</title><subtitle>A digital journey into my professional career &amp; projects</subtitle><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><entry><title type="html">Local Monitoring Stack for Kubernetes</title><link href="http://localhost:4000/local-monitoring-env/" rel="alternate" type="text/html" title="Local Monitoring Stack for Kubernetes" /><published>2025-07-26T18:32:04+02:00</published><updated>2025-07-26T18:32:04+02:00</updated><id>http://localhost:4000/local-monitoring-env</id><content type="html" xml:base="http://localhost:4000/local-monitoring-env/"><![CDATA[<h1 id="-local-monitoring-stack-for-kubernetes-prometheus--grafana--kafka">📡 Local Monitoring Stack for Kubernetes (Prometheus + Grafana + Kafka)</h1>

<p>https://github.com/leobip/monitoring.git</p>

<p>Welcome! 👋
This project sets up a local monitoring stack based on Prometheus, Grafana, and Kafka (with Kafka UI), using Helm charts and persistent volumes for durability.</p>

<p>Whether you’re experimenting with Kubernetes, developing custom controllers, or just want to see your cluster’s activity in real time — this guide has got you covered.
By the end, you’ll have a working environment where:</p>

<p>Prometheus collects metrics from your apps and infrastructure 🧲</p>

<p>Grafana helps you visualize those metrics with beautiful dashboards 📊</p>

<p>Kafka acts as a telemetry backbone, and Kafka-UI lets you explore the events flowing through it 🔄</p>

<p>This setup runs entirely on your local machine, making it ideal for testing and development — no cloud account or external services required!</p>

<hr />

<h2 id="-what-youll-get">🚀 What You’ll Get</h2>

<p>Once deployed, your local monitoring stack will include:</p>

<p>✅ A Prometheus instance, scraping metrics on port 30090</p>

<p>✅ A Grafana dashboard, accessible at localhost:30095</p>

<p>✅ A Kafka broker with persistent volumes</p>

<p>✅ Kafka UI at localhost:30096 to inspect topics and messages</p>

<p>✅ A health check script to ensure everything is up and running</p>

<hr />

<h2 id="-prometheus--grafana">📦 Prometheus + Grafana</h2>

<p>We’ll use the official Helm charts from Bitnami and Prometheus Community, with a few tweaks for local development and persistence. See values files for config details.</p>

<h2 id="-kafka--kafka-ui">🧱 Kafka + Kafka UI</h2>

<p>This section helps you install Kafka in plaintext mode, along with a lightweight UI to browse topics and messages.</p>

<p>Persistent volumes are enabled so your topics and messages stick around across Minikube restarts.</p>

<hr />

<h2 id="-folder-structure">🧱 Folder Structure</h2>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>monitoring/
├── deploy-all.sh <span class="c"># Script to install all components</span>
├── pv/ <span class="c"># Persistent volume manifests</span>
│ ├── kafka-pv.yaml
│ ├── prometheus-pv.yaml
│ └── grafana-pv.yaml
└── values/ <span class="c"># Helm values for each component</span>
  ├── kafka-values.yaml
  ├── kafka-ui-values.yaml
  ├── prometheus-values.yaml
  └── grafana-values.yaml
</code></pre></div></div>

<hr />

<h2 id="️-prerequisites">🛠️ Prerequisites</h2>

<p>Make sure you have the following installed:</p>

<ul>
  <li><a href="https://minikube.sigs.k8s.io/">Minikube</a></li>
  <li><a href="https://kubernetes.io/docs/tasks/tools/">kubectl</a></li>
  <li><a href="https://helm.sh/docs/intro/install/">Helm</a></li>
</ul>

<blockquote>
  <p>This setup assumes you’re running Kubernetes locally with Minikube.</p>
</blockquote>

<hr />

<h2 id="-installation">🚀 Installation</h2>

<h3 id="1-start-minikube">1.– Start Minikube</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube start <span class="nt">--memory</span><span class="o">=</span>4g <span class="nt">--cpus</span><span class="o">=</span>2
</code></pre></div></div>

<h3 id="2--add-helm-repositories">2.- Add Helm repositories</h3>

<ul>
  <li>This step is added in the script: Just uncomment de section</li>
</ul>

<h3 id="3--run-the-install-script">3.- Run the install script</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">cd </span>monitoring
<span class="nb">chmod</span> +x deploy-all.sh
./deploy-all.sh
</code></pre></div></div>

<ul>
  <li>This script will:
    <ul>
      <li>Create a monitoring namespace.</li>
      <li>Apply persistent volumes from pv/.</li>
    </ul>
  </li>
</ul>

<h2 id="-access-to-monitoring-tools">📋 Access to Monitoring Tools</h2>

<table>
  <thead>
    <tr>
      <th>Tool</th>
      <th>External Access (NodePort)</th>
      <th>Internal Access (Cluster DNS)</th>
      <th>Important Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Grafana</strong></td>
      <td><a href="http://192.168.49.2:30095">http://192.168.49.2:30095</a></td>
      <td><code class="language-plaintext highlighter-rouge">grafana.monitoring.svc.cluster.local</code></td>
      <td>- User: <code class="language-plaintext highlighter-rouge">admin</code> <br /> - Get password:<br /> <code class="language-plaintext highlighter-rouge">kubectl get secret -n monitoring grafana -o jsonpath="{.data.admin-password}" \| base64 --decode</code></td>
    </tr>
    <tr>
      <td><strong>Kafka</strong></td>
      <td>See ports with:<br /><code class="language-plaintext highlighter-rouge">kubectl get svc -n monitoring -l "app.kubernetes.io/instance=kafka,app.kubernetes.io/component=kafka,pod" -o jsonpath='{.items[*].spec.ports[0].nodePort}'</code></td>
      <td>- Client: <code class="language-plaintext highlighter-rouge">kafka.monitoring.svc.cluster.local:9092</code><br />- Brokers: <code class="language-plaintext highlighter-rouge">kafka-controller-0/1/2.kafka-controller-headless.monitoring.svc.cluster.local:9092</code></td>
      <td>- KRaft enabled<br />- EXTERNAL listener enabled<br />- Run a client with:<br /><code class="language-plaintext highlighter-rouge">kubectl run kafka-client --rm -it --image docker.io/bitnami/kafka:4.0.0-debian-12-r8 -n monitoring -- bash</code></td>
    </tr>
    <tr>
      <td><strong>Prometheus</strong></td>
      <td>Run:<br /><code class="language-plaintext highlighter-rouge">export NODE_PORT=$(kubectl get svc -n monitoring prometheus-server -o jsonpath="{.spec.ports[0].nodePort}")</code><br /><code class="language-plaintext highlighter-rouge">export NODE_IP=$(kubectl get nodes -o jsonpath="{.items[0].status.addresses[0].address}")</code><br /><code class="language-plaintext highlighter-rouge">echo http://$NODE_IP:$NODE_PORT</code></td>
      <td><code class="language-plaintext highlighter-rouge">prometheus-server.monitoring.svc.cluster.local</code></td>
      <td>- Server and AlertManager available<br />- AlertManager: port-forward:<br /><code class="language-plaintext highlighter-rouge">kubectl port-forward -n monitoring svc/prometheus-alertmanager 9093</code><br />- PushGateway: port-forward:<br /><code class="language-plaintext highlighter-rouge">kubectl port-forward -n monitoring svc/prometheus-prometheus-pushgateway 9091</code></td>
    </tr>
  </tbody>
</table>

<p>✅ Additional Notes</p>

<ul>
  <li>Minikube IP: 192.168.49.2 (verify with minikube ip if needed)</li>
  <li>Namespace: monitoring</li>
  <li>PVCs applied: grafana-pvc, kafka-pv, prometheus-pvc</li>
</ul>

<hr />

<h2 id="-verify-your-setup">🎯 Verify Your Setup</h2>

<p>Let’s make sure everything is working! You’ll check that Prometheus, Grafana, Kafka, and Kafka UI are all running and accessible via NodePorts.</p>

<h2 id="-accessing-tools-from-host-minikube--docker-on-macos">🔍 Accessing Tools from Host (Minikube + Docker on macOS)</h2>

<ul>
  <li>By default, services exposed via NodePort in Minikube may not be directly accessible from your host when using the Docker driver on macOS. This is due to networking limitations: the NodePort is exposed inside the Minikube VM/container, not on your host machine’s network.</li>
</ul>

<h3 id="get-the-name-of-the-tools-pods">Get the name of the tools pods</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❯ kubectl get svc <span class="nt">-n</span> monitoring
NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP    PORT<span class="o">(</span>S<span class="o">)</span>                      AGE
grafana                               NodePort    10.102.51.68     &lt;none&gt;         80:30095/TCP                 29m
kafka                                 ClusterIP   10.100.118.216   &lt;none&gt;         9092/TCP,9095/TCP            46m
kafka-controller-0-external           NodePort    10.109.227.109   192.168.49.2   9094:30092/TCP               46m
kafka-controller-1-external           NodePort    10.97.149.130    192.168.49.2   9094:30093/TCP               46m
kafka-controller-2-external           NodePort    10.99.194.34     192.168.49.2   9094:30094/TCP               46m
kafka-controller-headless             ClusterIP   None             &lt;none&gt;         9094/TCP,9092/TCP,9093/TCP   46m
kafka-jmx-metrics                     ClusterIP   10.99.29.148     &lt;none&gt;         5556/TCP                     46m
prometheus-alertmanager               ClusterIP   10.103.180.130   &lt;none&gt;         9093/TCP                     46m
prometheus-alertmanager-headless      ClusterIP   None             &lt;none&gt;         9093/TCP                     46m
prometheus-kube-state-metrics         ClusterIP   10.102.171.116   &lt;none&gt;         8080/TCP                     46m
prometheus-prometheus-node-exporter   ClusterIP   10.97.14.115     &lt;none&gt;         9100/TCP                     46m
prometheus-prometheus-pushgateway     ClusterIP   10.101.189.12    &lt;none&gt;         9091/TCP                     46m
prometheus-server                     NodePort    10.104.67.195    &lt;none&gt;         80:30090/TCP                 46m
</code></pre></div></div>

<h3 id="example">Example</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get svc <span class="nt">-n</span> monitoring grafana

NAME      TYPE       CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>        AGE
grafana   NodePort   10.102.51.68   &lt;none&gt;        80:30095/TCP   34m


kubectl get svc <span class="nt">-n</span> monitoring prometheus-server

NAME         TYPE       CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>          AGE
prometheus   NodePort   10.98.27.101   &lt;none&gt;        9090:31090/TCP   45m


kubectl get svc <span class="nt">-n</span> monitoring kafka-ui

NAME       TYPE       CLUSTER-IP     EXTERNAL-IP   PORT<span class="o">(</span>S<span class="o">)</span>          AGE
kafka-ui   NodePort   10.96.220.89   &lt;none&gt;        8080:30096/TCP   19m

</code></pre></div></div>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># ⚠️ IP may change on restart (check again)</span>
minikube ip
192.168.49.2
</code></pre></div></div>

<ul>
  <li><strong><em>You might expect <code class="language-plaintext highlighter-rouge">curl &lt;http://192.168.49.2:30095&gt;</code> to work, but it doesn’t respond.</em></strong></li>
</ul>

<h3 id="-option-1-minikube-service-temporary">🧪 Option 1: minikube service (Temporary)</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Grafana</span>
minikube service grafana <span class="nt">-n</span> monitoring

<span class="c"># Prometheus</span>
minikube service prometheus-server <span class="nt">-n</span> monitoring

<span class="c"># Kafka-ui</span>
minikube service kafka-ui <span class="nt">-n</span> monitoring

</code></pre></div></div>

<ul>
  <li>This opens a temporary proxy and shows a localhost URL like:</li>
</ul>

<pre><code class="language-psql"># Grafana
|------------|---------|-------------|---------------------------|
| NAMESPACE  |  NAME   | TARGET PORT |            URL            |
|------------|---------|-------------|---------------------------|
| monitoring | grafana | service/80  | http://192.168.49.2:30095 |
|------------|---------|-------------|---------------------------|
🏃  Starting tunnel for service grafana.
|------------|---------|-------------|------------------------|
| NAMESPACE  |  NAME   | TARGET PORT |          URL           |
|------------|---------|-------------|------------------------|
| monitoring | grafana |             | http://127.0.0.1:56851 |
|------------|---------|-------------|------------------------|
🎉  Opening service monitoring/grafana in default browser...
❗  Because you are using a Docker driver on darwin, the terminal needs to be open to run it.


# Prometheus
|------------|-------------------|-------------|---------------------------|
| NAMESPACE  |       NAME        | TARGET PORT |            URL            |
|------------|-------------------|-------------|---------------------------|
| monitoring | prometheus-server | http/80     | http://192.168.49.2:30090 |
|------------|-------------------|-------------|---------------------------|
🏃  Starting tunnel for service prometheus-server.
|------------|-------------------|-------------|------------------------|
| NAMESPACE  |       NAME        | TARGET PORT |          URL           |
|------------|-------------------|-------------|------------------------|
| monitoring | prometheus-server |             | http://127.0.0.1:56409 |
|------------|-------------------|-------------|------------------------|
🎉  Opening service monitoring/prometheus-server in default browser...
❗  Because you are using a Docker driver on darwin, the terminal needs to be open to run it.


# kafka
|------------|----------|-------------|---------------------------|
| NAMESPACE  |   NAME   | TARGET PORT |            URL            |
|------------|----------|-------------|---------------------------|
| monitoring | kafka-ui | http/8080   | http://192.168.49.2:30096 |
|------------|----------|-------------|---------------------------|
🏃  Starting tunnel for service kafka-ui.
|------------|----------|-------------|------------------------|
| NAMESPACE  |   NAME   | TARGET PORT |          URL           |
|------------|----------|-------------|------------------------|
| monitoring | kafka-ui |             | http://127.0.0.1:64903 |
|------------|----------|-------------|------------------------|

</code></pre>

<ul>
  <li>✅ Works immediately, opens browser
    <ul>
      <li>❗ Needs terminal to stay open (as it runs a local tunnel)</li>
      <li>❗ Not script-friendly or persistent</li>
    </ul>
  </li>
</ul>

<h3 id="persistent">persistent</h3>

<p>🛠 Option 2: kubectl port-forward (Persistent while running)</p>

<ul>
  <li>You can forward the Grafana service to a local port
    <ul>
      <li>With Lens, Openlens, K9s, etc</li>
      <li>Or via kubectl cmd in terminal</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl port-forward <span class="nt">-n</span> monitoring svc/grafana 30095:80

kubectl port-forward <span class="nt">-n</span> monitoring svc/prometheus 9090:9090

kubectl port-forward svc/kafka-ui 8080:8080 <span class="nt">-n</span> monitoring

</code></pre></div></div>

<ul>
  <li>
    <p><strong><em>NOTE: Yopu have to stop the temporary proxy with ctrl-c before stop minikube, and execute again on restart</em></strong></p>
  </li>
  <li>
    <p>Then visit (In this example):</p>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># grafana</span>
http://localhost:30095

<span class="c"># prometheus</span>
http://localhost:9090

<span class="c"># kafka</span>
http://localhost:9093

</code></pre></div></div>

<ul>
  <li><strong>Login</strong>
    <ul>
      <li><em>Grafana:</em>
        <ul>
          <li>user: admin</li>
          <li>password: admin***</li>
        </ul>
      </li>
    </ul>
  </li>
  <li>✅ Works reliably
    <ul>
      <li>❗ Still requires the terminal to stay open</li>
      <li>❗ Better suited for dev workflows, or when using tools like Lens/K9s which manage this automatically</li>
    </ul>
  </li>
</ul>

<h3 id="-option-3-minikube-tunnel-recommended-for-real-external-access">🛡 Option 3: minikube tunnel (Recommended for real external access)</h3>

<ul>
  <li>Only if you define type: as LoadBalancer instead of NodePort</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube tunnel
</code></pre></div></div>

<ul>
  <li>Exposes NodePort and LoadBalancer services to your macOS host.</li>
  <li>Runs in background (but requires admin privileges).</li>
  <li>Makes the minikube ip + NodePort combination work:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>curl http://192.168.49.2:30095
...
</code></pre></div></div>

<ul>
  <li><strong>✅ Best if you want persistent access via actual cluster IP</strong></li>
  <li><strong>⚠️ You’ll need to keep the tunnel running in a terminal</strong></li>
</ul>

<h3 id="summary">Summary</h3>

<table>
  <thead>
    <tr>
      <th>Method</th>
      <th>Persistent</th>
      <th>Scriptable</th>
      <th>Requires open terminal</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">minikube service</code></td>
      <td>❌</td>
      <td>❌</td>
      <td>✅</td>
      <td>Great for quick UI testing</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">kubectl port-forward</code></td>
      <td>❌</td>
      <td>✅</td>
      <td>✅</td>
      <td>Ideal during dev/debug</td>
    </tr>
    <tr>
      <td><code class="language-plaintext highlighter-rouge">minikube tunnel</code></td>
      <td>✅</td>
      <td>✅</td>
      <td>✅ (background)</td>
      <td>Best for stable external access</td>
    </tr>
  </tbody>
</table>

<h3 id="tools-summary">Tools Summary</h3>

<table>
  <thead>
    <tr>
      <th>Service</th>
      <th>Method</th>
      <th>Persistent</th>
      <th>Host Access</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td><strong>Grafana</strong></td>
      <td><code class="language-plaintext highlighter-rouge">minikube service</code></td>
      <td>❌</td>
      <td>✅</td>
      <td>UI test only</td>
    </tr>
    <tr>
      <td> </td>
      <td><code class="language-plaintext highlighter-rouge">kubectl port-fwd</code></td>
      <td>❌</td>
      <td>✅</td>
      <td>Dev access</td>
    </tr>
    <tr>
      <td> </td>
      <td><code class="language-plaintext highlighter-rouge">minikube tunnel</code></td>
      <td>✅</td>
      <td>✅</td>
      <td>Needed for NodePort from host</td>
    </tr>
    <tr>
      <td><strong>Prometheus</strong></td>
      <td>Same as above</td>
      <td>Same</td>
      <td>Same</td>
      <td>Accessible at port 9090</td>
    </tr>
    <tr>
      <td><strong>Kafka</strong></td>
      <td><code class="language-plaintext highlighter-rouge">port-fwd 9093</code></td>
      <td>❌</td>
      <td>✅ (TLS)</td>
      <td>For testing with TLS listener</td>
    </tr>
    <tr>
      <td> </td>
      <td><code class="language-plaintext highlighter-rouge">minikube tunnel</code></td>
      <td>✅</td>
      <td>✅</td>
      <td>Needed for TLS access from host tools</td>
    </tr>
  </tbody>
</table>

<h2 id="-stopping-and-restarting-minikube-safely">🔄 Stopping and Restarting Minikube Safely</h2>

<p><strong><em>♻️ Minikube Lifecycle (Shutdown / Restart)</em></strong></p>

<p>To safely shut down and restart your monitoring stack without losing data or encountering errors:</p>

<h3 id="-stop-minikube">✅ Stop Minikube</h3>

<ul>
  <li>Use minikube stop instead of deleting the cluster:
    <ul>
      <li>This safely shuts down the VM/container.</li>
      <li>PVCs and all service configurations remain intact.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube stop
</code></pre></div></div>

<h3 id="-start-again-later">✅ Start Again Later</h3>

<ul>
  <li>This restores the full state, including your deployed services, PVCs, and Helm releases.
    <ul>
      <li>All NodePorts and persistent data remain available.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube start
</code></pre></div></div>

<p><strong><em>⚠️ Do Not Use</em></strong></p>

<ul>
  <li>❌ This deletes all volumes, pods, secrets, configs — use only if you want a clean reset.</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube delete
</code></pre></div></div>

<h3 id="-check-status">🧪 Check Status</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pods <span class="nt">-n</span> monitoring
</code></pre></div></div>

<ul>
  <li>If pods don’t come up correctly (e.g., CrashLoopBackOff), you may need to:
    <ul>
      <li>Reapply deploy-all.sh</li>
      <li>
        <p>Re-check Minikube disk availability with:</p>

        <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>minikube ssh
<span class="nb">df</span> <span class="nt">-h</span>
</code></pre></div>        </div>
      </li>
    </ul>
  </li>
</ul>

<h3 id="-persistent-volumes--restarting-notes">🔒 Persistent Volumes &amp; Restarting Notes</h3>

<table>
  <thead>
    <tr>
      <th>Component</th>
      <th>Persistent?</th>
      <th>How It’s Stored</th>
      <th>Notes</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>Prometheus</td>
      <td>✅</td>
      <td>PVC → HostPath on VM</td>
      <td>Config &amp; scraped metrics preserved across reboots</td>
    </tr>
    <tr>
      <td>Grafana</td>
      <td>✅</td>
      <td>PVC (grafana-pvc)</td>
      <td>Dashboards, settings are saved</td>
    </tr>
    <tr>
      <td>Kafka</td>
      <td>✅</td>
      <td>PVC per broker/controller</td>
      <td>Topic data survives restart. Must wait for all brokers to rejoin.</td>
    </tr>
    <tr>
      <td>Kafka-UI</td>
      <td>❌</td>
      <td>Ephemeral</td>
      <td>Will restart fresh; doesn’t affect Kafka state</td>
    </tr>
  </tbody>
</table>

<h3 id="-optional-restart-deploy-allsh-if-needed">🔁 Optional: Restart deploy-all.sh (if needed)</h3>

<ul>
  <li>You can safely re-run the script to reapply Helm charts and PVCs:
    <ul>
      <li>💡 Helm is idempotent — it will upgrade existing releases without data loss if PVCs exist.</li>
    </ul>
  </li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./deploy-all.sh
</code></pre></div></div>

<h3 id="-tip-back-up-persistent-data-optional">📁 Tip: Back Up Persistent Data (Optional)</h3>

<ul>
  <li>To snapshot your PVCs before restarting or for backup purposes:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pvc <span class="nt">-n</span> monitoring
</code></pre></div></div>

<ul>
  <li>For example:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl <span class="nb">cp </span>monitoring/prometheus-server-0:/opt/bitnami/prometheus/data ./backup-prometheus-data
</code></pre></div></div>

<h2 id="-final-tip-automate-health-checks-optional">🧠 Final Tip: Automate Health Checks (Optional)</h2>

<p>To quickly check if your monitoring stack is up and running, you can either:</p>

<h3 id="-option-a-use-the-health-check-script-recommended"><strong><em>✅ Option A: Use the health check script (recommended)</em></strong></h3>

<ul>
  <li>Run the provided script to verify key components like Prometheus, Grafana, Kafka and Kafka-UI:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>./check-health.sh
</code></pre></div></div>

<ul>
  <li>Response</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>❯ ./check-health.sh

⏳ Checking health of monitoring components <span class="k">in </span>namespace: monitoring
🔍 prometheus-server...
deployment <span class="s2">"prometheus-server"</span> successfully rolled out
✅ prometheus-server is healthy
🔍 grafana...
deployment <span class="s2">"grafana"</span> successfully rolled out
✅ grafana is healthy
🔍 kafka-ui...
deployment <span class="s2">"kafka-ui"</span> successfully rolled out
✅ kafka-ui is healthy
🔍 kafka-controller...
statefulset rolling update <span class="nb">complete </span>3 pods at revision kafka-controller-98bc6557b...
✅ kafka-controller is healthy
✅ Health check completed.
</code></pre></div></div>

<ul>
  <li>If components are not found or in a bad state, the script will print warnings accordingly.</li>
  <li>You can edit the script to match the names of your deployments or statefulsets, depending on your YAMLs.</li>
</ul>

<h3 id="-option-b-check-manually-with-kubectl"><strong><em>🔍 Option B: Check manually with kubectl</em></strong></h3>

<p>If you prefer manual inspection or want to verify specific resources:</p>

<ul>
  <li>List all pods in the monitoring namespace:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get pods <span class="nt">-n</span> monitoring
</code></pre></div></div>

<ul>
  <li>You should see something like:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                                READY   STATUS    RESTARTS        AGE
grafana-57554dd88-rc8z4                             1/1     Running   0               3h11m
kafka-controller-0                                  1/1     Running   0               175m
kafka-controller-1                                  1/1     Running   0               175m
kafka-controller-2                                  1/1     Running   0               175m
kafka-ui-5448964747-ds2bd                           1/1     Running   0               171m
prometheus-alertmanager-0                           1/1     Running   1 <span class="o">(</span>4h59m ago<span class="o">)</span>   24h
prometheus-kube-state-metrics-7f796b7d44-89mjd      1/1     Running   1 <span class="o">(</span>4h59m ago<span class="o">)</span>   24h
prometheus-prometheus-node-exporter-cltc4           1/1     Running   1 <span class="o">(</span>4h59m ago<span class="o">)</span>   24h
prometheus-prometheus-pushgateway-d4f8cb767-nwtn9   1/1     Running   1 <span class="o">(</span>4h59m ago<span class="o">)</span>   24h
prometheus-server-79798b4ff6-7g55g                  2/2     Running   2 <span class="o">(</span>4h59m ago<span class="o">)</span>   24h
...
</code></pre></div></div>

<ul>
  <li>Check services and their ports:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>kubectl get svc <span class="nt">-n</span> monitoring
</code></pre></div></div>

<ul>
  <li>Look for NodePort services exposing the UIs:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>NAME                                  TYPE        CLUSTER-IP       EXTERNAL-IP    PORT<span class="o">(</span>S<span class="o">)</span>                      AGE
grafana                               NodePort    10.104.174.27    &lt;none&gt;         80:30095/TCP                 3h11m
kafka                                 ClusterIP   10.106.201.77    &lt;none&gt;         9092/TCP,9095/TCP            175m
kafka-controller-0-external           NodePort    10.105.143.201   192.168.49.2   9094:30092/TCP               175m
kafka-controller-1-external           NodePort    10.101.82.105    192.168.49.2   9094:30093/TCP               175m
kafka-controller-2-external           NodePort    10.97.107.152    192.168.49.2   9094:30094/TCP               175m
kafka-controller-headless             ClusterIP   None             &lt;none&gt;         9094/TCP,9092/TCP,9093/TCP   175m
kafka-ui                              NodePort    10.100.56.227    &lt;none&gt;         8080:30096/TCP               171m
prometheus-alertmanager               ClusterIP   10.103.180.130   &lt;none&gt;         9093/TCP                     24h
prometheus-alertmanager-headless      ClusterIP   None             &lt;none&gt;         9093/TCP                     24h
prometheus-kube-state-metrics         ClusterIP   10.102.171.116   &lt;none&gt;         8080/TCP                     24h
prometheus-prometheus-node-exporter   ClusterIP   10.97.14.115     &lt;none&gt;         9100/TCP                     24h
prometheus-prometheus-pushgateway     ClusterIP   10.101.189.12    &lt;none&gt;         9091/TCP                     24h
prometheus-server                     NodePort    10.104.67.195    &lt;none&gt;         80:30090/TCP                 24h
</code></pre></div></div>

<ul>
  <li>Then, access the dashboards using <code class="language-plaintext highlighter-rouge">http://&lt;minikube-ip&gt;:&lt;nodeport&gt;</code>. For example:
    <ul>
      <li>Grafana: <a href="http://localhost:30095">http://localhost:30095</a></li>
      <li>Prometheus: <a href="http://localhost:30090">http://localhost:30090</a></li>
      <li>Kafka UI: <a href="http://localhost:30096">http://localhost:30096</a></li>
    </ul>
  </li>
  <li><strong>Use minikube ip to get your cluster IP if needed.</strong></li>
</ul>]]></content><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><summary type="html"><![CDATA[📡 Local Monitoring Stack for Kubernetes (Prometheus + Grafana + Kafka)]]></summary><media:thumbnail xmlns:media="http://search.yahoo.com/mrss/" url="http://localhost:4000/images/projects/2025-07-26-monitoring.png" /><media:content medium="image" url="http://localhost:4000/images/projects/2025-07-26-monitoring.png" xmlns:media="http://search.yahoo.com/mrss/" /></entry><entry><title type="html">🌳 Branching Model &amp;amp; 📌 Semantic Versioning in Git Workflows</title><link href="http://localhost:4000/git/cicd/versioning/semantic-versioning/" rel="alternate" type="text/html" title="🌳 Branching Model &amp;amp; 📌 Semantic Versioning in Git Workflows" /><published>2025-04-25T19:30:00+02:00</published><updated>2025-04-25T19:30:00+02:00</updated><id>http://localhost:4000/git/cicd/versioning/semantic-versioning</id><content type="html" xml:base="http://localhost:4000/git/cicd/versioning/semantic-versioning/"><![CDATA[<p>Managing branches and releases efficiently is crucial for maintaining <strong>code quality, traceability, and smooth deployments</strong>. In this article, we’ll explain how to structure your Git workflow using <strong>branches for different purposes</strong> and how to apply <strong>Semantic Versioning (SemVer)</strong> to tag releases.</p>

<figure style="display: flex; flex-direction: column; align-items: center;">
  <img src="/assets/images/semantic-versioning-banner.jpeg" style="max-width:100%; height:auto;" />
  <figcaption style="margin-top: 0.5em; font-style: italic;">
  </figcaption>
</figure>

<h2 id="-branching-strategy">🌳 Branching Strategy</h2>

<p>We adopt a simplified <strong>Git Flow–inspired model</strong>:</p>

<ul>
  <li><strong><code class="language-plaintext highlighter-rouge">main</code> branch</strong> → Always reflects the latest <strong>stable production-ready code</strong>.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">dev</code> branch</strong> → Integration branch for ongoing development.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">feature/*</code> branches</strong> → Temporary branches for new features, merged back into <code class="language-plaintext highlighter-rouge">dev</code>.</li>
  <li><strong><code class="language-plaintext highlighter-rouge">hotfix/*</code> branches</strong> → For urgent fixes, branched directly from <code class="language-plaintext highlighter-rouge">main</code>, then merged back into both <code class="language-plaintext highlighter-rouge">main</code> and <code class="language-plaintext highlighter-rouge">dev</code>.</li>
</ul>

<h3 id="example-workflow">Example Workflow</h3>

<pre><code class="language-mermaid">gitGraph
   commit id: "Init"
   branch dev
   checkout dev
   commit id: "Feature A start"
   branch feature/A
   commit id: "WIP A1"
   commit id: "WIP A2"
   checkout dev
   merge feature/A id: "Merge A"
   commit id: "Stabilization"
   checkout main
   merge dev id: "Release v1.0.0"
   branch hotfix/urgent
   commit id: "Hotfix"
   checkout main
   merge hotfix/urgent id: "Release v1.0.1"
   checkout dev
   merge hotfix/urgent

## 📌 Semantic Versioning (SemVer)

We use Semantic Versioning 2.0.0 format:

```bash
MAJOR.MINOR.PATCH
</code></pre>

<ul>
  <li>MAJOR → Breaking changes (e.g., API change, backward-incompatible refactor).</li>
  <li>MINOR → New features, backward-compatible.</li>
  <li>PATCH → Bug fixes, backward-compatible.</li>
</ul>

<h3 id="examples">Examples</h3>

<ul>
  <li>1.0.0 → Initial stable release.</li>
  <li>1.1.0 → Adds new features without breaking existing functionality.</li>
  <li>1.1.1 → Fixes a bug without changing functionality.</li>
</ul>

<h2 id="-tagging-releases-in-git">🏷 Tagging Releases in Git</h2>

<p>Each release is tagged with its SemVer version:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c"># Tagging a release</span>
git tag <span class="nt">-a</span> v1.0.0 <span class="nt">-m</span> <span class="s2">"Release v1.0.0 - Initial stable release"</span>
git push origin v1.0.0
</code></pre></div></div>

<p>This allows:</p>

<ul>
  <li>CI/CD pipelines to build artifacts based on tags.</li>
  <li>Traceability of deployments.</li>
  <li>Easy rollback to previous versions.</li>
</ul>

<hr />

<h2 id="-integration-with-cicd">🔗 Integration with CI/CD</h2>

<ul>
  <li>Development branch (dev) → triggers tests &amp; static analysis (e.g., SonarQube).</li>
  <li>Main branch (main) → triggers build + deployment pipeline.</li>
  <li>Tags (vX.Y.Z) → trigger release pipelines (e.g., publishing Docker images, Helm charts).</li>
</ul>

<hr />

<h3 id="-conclusion">✅ Conclusion</h3>

<p>By combining a clear branching strategy with Semantic Versioning, we ensure:</p>

<ul>
  <li>Predictable release cycles.</li>
  <li>Traceability of features and fixes.</li>
  <li>Alignment between Git workflow and CI/CD pipelines.</li>
</ul>

<p>This model scales from small projects to enterprise environments and integrates seamlessly with tools like SonarQube, GitHub Actions, and ArgoCD.</p>]]></content><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><category term="git" /><category term="cicd" /><category term="versioning" /><category term="branching" /><category term="git-flow" /><category term="semantic-versioning" /><summary type="html"><![CDATA[Managing branches and releases efficiently is crucial for maintaining code quality, traceability, and smooth deployments. In this article, we’ll explain how to structure your Git workflow using branches for different purposes and how to apply Semantic Versioning (SemVer) to tag releases.]]></summary></entry><entry><title type="html">⚙️💻 Building a Local Development, Testing &amp;amp; Deployment Environment</title><link href="http://localhost:4000/cicd/development/tools/deployment/local-dev-env/" rel="alternate" type="text/html" title="⚙️💻 Building a Local Development, Testing &amp;amp; Deployment Environment" /><published>2025-04-20T21:55:15+02:00</published><updated>2025-04-20T21:55:15+02:00</updated><id>http://localhost:4000/cicd/development/tools/deployment/local-dev-env</id><content type="html" xml:base="http://localhost:4000/cicd/development/tools/deployment/local-dev-env/"><![CDATA[<p>A well-structured <strong>local development environment</strong> is essential for improving code quality, automating testing, and streamlining deployments.<br />
In this guide, we will progressively build a <strong>local ecosystem</strong> for developers, adding essential tools step by step. The final goal is to create an environment that allows you to <strong>write, analyze, test, and deploy code efficiently</strong>.</p>

<figure style="display: flex; flex-direction: column; align-items: center;">
  <img src="/assets/images/local-dev-env-banner.webp" style="max-width:75%; height:auto;" />
  <figcaption style="margin-top: 0.5em; font-style: italic;">
  </figcaption>
</figure>

<p>This article serves as the <strong>central hub</strong> of the series — each tool (e.g., SonarQube, ArgoCD, Monitoring) will have its own dedicated post with installation details, while here we’ll explain <strong>how everything integrates together</strong>.</p>

<hr />

<h2 id="-planned-components">🗂 Planned Components</h2>

<ul>
  <li><strong>🔍 Code Analysis (SonarQube)</strong> – Static code analysis for code quality.</li>
  <li><strong>📝 Linting (SonarLint for IDEs)</strong> – Consistent coding standards in real-time.</li>
  <li><strong>🔄 Version Control (GitHub)</strong> – Branches, PRs, tags, semantic versioning (we’ll link a dedicated article).</li>
  <li><strong>⚡ CI/CD Pipelines (GitHub Actions)</strong> – Automated build &amp; test pipelines.</li>
  <li><strong>🚀 Deployment (ArgoCD)</strong> – GitOps-based application delivery.</li>
  <li><strong>📊 Monitoring (Prometheus, Grafana)</strong> – Observability for apps.</li>
</ul>

<hr />

<h2 id="-project-structure">📂 Project Structure</h2>

<p>Here’s the proposed folder layout for our environment:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>local-dev-environment/
│
├── sonarqube/                  <span class="c"># SonarQube setup and configuration</span>
│   ├── conf/                   <span class="c"># SonarQube config (sonar.properties, etc.)</span>
│   ├── data/                   <span class="c"># Persistent data storage</span>
│   ├── logs/                   <span class="c"># Log files</span>
│   └── extensions/             <span class="c"># Plugins &amp; extensions</span>
│
├── code-examples/              <span class="c"># Sample code for analysis &amp; testing</span>
│   └── python/
│       └── api-requests.py
│
├── tests/                      <span class="c"># Example unit tests</span>
│   └── test_example.py
│
├── .github/
│   ├── workflows/
│   │   └── sonarqube-analysis.yml  <span class="c"># Pipeline  </span>
│   └── actions-runner/             <span class="c"># Self-hosted GitHub Actions Runner</span>
│       └── run.sh                  <span class="c"># Script to start the runner</span>
│
├── docker-compose.yaml         <span class="c"># Compose file for multiple services</span>
├── README.md                   <span class="c"># Project documentation</span>
└── requirements.txt            <span class="c"># Dependencies</span>
...
... <span class="o">(</span><span class="k">in </span>development<span class="o">)</span>

</code></pre></div></div>

<h3 id="steps">Steps</h3>

<ul>
  <li>Create the folders and initialize the repository</li>
  <li>You can initialize the repository by running git init in the root folder of local-dev-environment.</li>
  <li>Push the code to your GitHub repository and link it here: <a href="https://github.com/leobip/local-dev-env.git">Project GitHub Repository</a></li>
</ul>

<p>This guide will start with SonarQube, a powerful tool for static code analysis, and expand as we integrate more tools.</p>

<h2 id="-static-code-analysis-with-sonarqube">🔍 Static Code Analysis with SonarQube</h2>

<p>We start our environment with SonarQube, a powerful static analysis tool that detects bugs, security vulnerabilities, and code smells.</p>

<p>Once SonarQube is running locally (via docker-compose), we can integrate it into our pipeline so that every push to the repository gets analyzed automatically.</p>

<ul>
  <li>👉 Detailed installation guide: <a href="/sonarqube/static%20analysis/tools/local-env-sonarqube/">SonarQube Setup Article</a></li>
</ul>

<h2 id="-github-actions--sonarqube-analysis-pipeline">⚡ GitHub Actions – SonarQube Analysis Pipeline</h2>

<p>As a first CI/CD integration, let’s configure a GitHub Actions workflow to run SonarQube scans on our code.
This pipeline runs on the dev branch — a common branching strategy where:</p>

<ul>
  <li>dev → integration branch for ongoing development</li>
  <li>main → stable production-ready branch</li>
  <li>feature/* → temporary branches for new features</li>
</ul>

<p>We’ll create a separate article on branching models, semantic versioning, and release workflows (to keep this guide focused).</p>

<ul>
  <li>👉 Detailed installation guide: <a href="/git/cicd/versioning/semantic-versioning/">Branching &amp; Semantic Versioning Article</a></li>
</ul>

<hr />

<h3 id="-setting-up-github-actions">🔧 Setting Up GitHub Actions</h3>

<ol>
  <li>Navigate to your repository on GitHub.</li>
  <li>Click on the <strong>Actions</strong> tab in the repository menu.</li>
  <li>If this is your first time, you’ll be prompted to configure a new workflow. Click <strong>“Set up this workflow yourself”</strong>.</li>
  <li>GitHub will open a YAML editor where you can define your first workflow.</li>
  <li>
    <p>Inside your repository, make sure you have the following directory structure:</p>

    <div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>.github/
  └── workflows/
      └── sonarqube-analysis.yml
</code></pre></div>    </div>
  </li>
</ol>

<p>This file will contain the pipeline configuration for SonarQube analysis.</p>

<h3 id="-add-sonarqube-token-to-github-secrets">🔑 Add SonarQube Token to GitHub Secrets</h3>

<p>For the workflow to authenticate with SonarQube, you need a token:</p>

<ul>
  <li>Generate a token in SonarQube:
    <ul>
      <li>Go to My Account → Security → Generate Tokens.</li>
      <li>Copy the generated token (you will not be able to see it again).</li>
    </ul>
  </li>
  <li>Add it to your GitHub repository secrets:
    <ul>
      <li>Open your GitHub repository.</li>
      <li>Go to Settings → Secrets and variables → Actions.</li>
      <li>Click New repository secret.</li>
      <li>Name it SONAR_TOKEN and paste the value from SonarQube.</li>
    </ul>
  </li>
  <li>Workflow File: .github/workflows/sonarqube-analysis.yml</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">name</span><span class="pi">:</span> <span class="s">SonarQube Analysis</span>

<span class="na">on</span><span class="pi">:</span>
  <span class="na">push</span><span class="pi">:</span>
    <span class="na">branches</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">dev</span>
  <span class="c1"># Uncomment below if you want to analyze PRs into main</span>
  <span class="c1"># pull_request:</span>
  <span class="c1">#   branches:</span>
  <span class="c1">#     - main</span>

<span class="na">jobs</span><span class="pi">:</span>
  <span class="na">sonarQube</span><span class="pi">:</span>
    <span class="na">runs-on</span><span class="pi">:</span> <span class="s">self-hosted</span>

    <span class="na">steps</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Checkout code</span>
        <span class="na">uses</span><span class="pi">:</span> <span class="s">actions/checkout@v4</span>

      <span class="pi">-</span> <span class="na">name</span><span class="pi">:</span> <span class="s">Run SonarScanner</span>
        <span class="na">run</span><span class="pi">:</span> <span class="pi">|</span>
          <span class="s">sonar-scanner \</span>
            <span class="s">-Dsonar.projectKey=chronos-desktop-app \</span>
            <span class="s">-Dsonar.sources=. \</span>
            <span class="s">-Dsonar.host.url=http://localhost:9001 \</span>
            <span class="s">-Dsonar.login=$</span>
</code></pre></div></div>

<h2 id="️-setting-up-the-actions-runner">🖥️ Setting Up the Actions Runner</h2>

<p>Since we’re running SonarQube locally, the pipeline needs a self-hosted GitHub Actions runner.</p>

<h3 id="steps-to-add-actions-runner">Steps to Add Actions Runner</h3>

<ul>
  <li>Create the folder:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">mkdir</span> <span class="nt">-p</span> .github/actions-runner
</code></pre></div></div>

<ul>
  <li>Inside, add the script run.sh:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>
<span class="nb">cd</span> .github/actions-runner
./run.sh

<span class="c"># Make it executable:</span>
<span class="nb">chmod</span> +x .github/actions-runner/run.sh

<span class="c"># Start the runner before pushing code:</span>
./github/actions-runner/run.sh
</code></pre></div></div>

<h3 id="️-important-notes">⚠️ Important Notes</h3>

<p>✅ SonarQube must be running → Since we deployed it via Docker Compose, containers will auto-restart after a reboot (unless stopped manually in Docker Desktop). You can always check in Docker Desktop or via docker ps.</p>

<p>✅ Start the runner before committing/pushing → If the runner isn’t running, GitHub won’t detect the workflow and the pipeline won’t execute.</p>

<p>✅ Branch strategy → For now, we trigger analysis only on dev. Later, we’ll extend this to main and release workflows.</p>

<h3 id="-key-points">🔑 Key Points</h3>

<ul>
  <li>runs-on: self-hosted → The job runs on a self-hosted runner (needed since we use local SonarQube).</li>
  <li>SONAR_TOKEN → Stored in GitHub Secrets, generated from SonarQube.</li>
  <li>Branching strategy → For now, we run scans on dev. Later, we may extend it to main or PRs.</li>
</ul>

<p>This ensures every code change on dev is scanned, keeping quality checks aligned with our development workflow.</p>

<h2 id="-next-steps">🚀 Next Steps</h2>

<ul>
  <li>Expand pipelines to include tests, builds, and deployments.</li>
  <li>Add ArgoCD to migrate and manage SonarQube in Kubernetes.</li>
  <li>Extend analysis pipelines for main branch with semantic versioning &amp; release tags.</li>
  <li>Integrate monitoring to visualize the health of our apps.</li>
</ul>

<p>This is just the first building block of our developer ecosystem. With each article, we’ll add another piece until the full puzzle comes together. 🧩</p>]]></content><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><category term="cicd" /><category term="development" /><category term="tools" /><category term="deployment" /><category term="edge case" /><summary type="html"><![CDATA[A well-structured local development environment is essential for improving code quality, automating testing, and streamlining deployments. In this guide, we will progressively build a local ecosystem for developers, adding essential tools step by step. The final goal is to create an environment that allows you to write, analyze, test, and deploy code efficiently.]]></summary></entry><entry><title type="html">🐍 PYTHON - Tools Library</title><link href="http://localhost:4000/layout/python/help-tools/python-library/" rel="alternate" type="text/html" title="🐍 PYTHON - Tools Library" /><published>2024-12-10T00:00:00+01:00</published><updated>2024-12-10T00:00:00+01:00</updated><id>http://localhost:4000/layout/python/help-tools/python-library</id><content type="html" xml:base="http://localhost:4000/layout/python/help-tools/python-library/"><![CDATA[<figure style="display: flex; flex-direction: column; align-items: center;">
  <img src="/assets/images/2024-12-10-python-library.png" style="max-width:100%; height:auto;" />
  <figcaption style="margin-top: 0.5em; font-style: italic;">
  </figcaption>
</figure>

<h2 id="introduction">Introduction</h2>

<p>In this post, <strong>Python Tools Library</strong>, I’ll be collecting and sharing tools that I’ve developed to make my day-to-day work easier, cover specific needs, or simply explore ideas that might simplify common tasks.</p>

<p>The goal is to share knowledge in a practical way. All tools will be stored in the <strong>same GitHub repository</strong>, and the blog will indicate which tool was added most recently so readers can easily track updates.</p>

<hr />

<h2 id="json-full-search">JSon Full Search</h2>

<figure style="display: flex; flex-direction: column; align-items: center;">
  <img src="/assets/images/2024-12-10-python-json-small.webp" style="max-width:60%; height:auto;" />
  <figcaption style="margin-top: 0.5em; font-style: italic;">
    Image generated with AI (custom design).
  </figcaption>
</figure>

<h3 id="description">Description</h3>

<p>As the name suggests, this is a function designed to parse a JSON file and extract the value of a given key. It works recursively, which means it can traverse nested dictionaries and retrieve either a single value or an entire dictionary depending on the requested key.</p>

<p>This makes it especially useful when working with deeply nested JSON structures. Here I’ll explain how to use it and document future improvements.</p>

<h3 id="example-json">Example JSON</h3>

<div class="language-json highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="w">
</span><span class="p">{</span><span class="w">
    </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"John Doe"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"age"</span><span class="p">:</span><span class="w"> </span><span class="mi">30</span><span class="p">,</span><span class="w">
    </span><span class="nl">"address"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"street"</span><span class="p">:</span><span class="w"> </span><span class="s2">"123 Main St"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"city"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Anytown"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"state"</span><span class="p">:</span><span class="w"> </span><span class="s2">"CA"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"country"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"United States"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"code"</span><span class="p">:</span><span class="w"> </span><span class="s2">"US"</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">},</span><span class="w">
    </span><span class="nl">"email"</span><span class="p">:</span><span class="w"> </span><span class="s2">"john.doe@example.com"</span><span class="p">,</span><span class="w">
    </span><span class="nl">"phone_numbers"</span><span class="p">:</span><span class="w"> </span><span class="p">[</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"home"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"number"</span><span class="p">:</span><span class="w"> </span><span class="s2">"555-555-5555"</span><span class="w">
        </span><span class="p">},</span><span class="w">
        </span><span class="p">{</span><span class="w">
            </span><span class="nl">"type"</span><span class="p">:</span><span class="w"> </span><span class="s2">"work"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"number"</span><span class="p">:</span><span class="w"> </span><span class="s2">"555-555-5556"</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">],</span><span class="w">
    </span><span class="nl">"employment"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
        </span><span class="nl">"job_title"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Software Engineer"</span><span class="p">,</span><span class="w">
        </span><span class="nl">"department"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
            </span><span class="nl">"name"</span><span class="p">:</span><span class="w"> </span><span class="s2">"Engineering"</span><span class="p">,</span><span class="w">
            </span><span class="nl">"location"</span><span class="p">:</span><span class="w"> </span><span class="p">{</span><span class="w">
                </span><span class="nl">"building"</span><span class="p">:</span><span class="w"> </span><span class="s2">"HQ"</span><span class="p">,</span><span class="w">
                </span><span class="nl">"floor"</span><span class="p">:</span><span class="w"> </span><span class="mi">5</span><span class="w">
            </span><span class="p">}</span><span class="w">
        </span><span class="p">}</span><span class="w">
    </span><span class="p">}</span><span class="w">
</span><span class="p">}</span><span class="w">

</span></code></pre></div></div>

<h3 id="usage">Usage</h3>

<p>From the example above, you can extract the value of the key city: “Anytown”.
You can also extract the full nested dictionary address: { … }.</p>

<h3 id="pending-features">Pending features</h3>

<ul>
  <li>Counter for cases with duplicate keys (e.g., multiple name fields).</li>
  <li>Key identifiers to handle repeated keys.</li>
</ul>

<h3 id="features">Features</h3>

<ul>
  <li><strong>Tecnology:</strong> Python</li>
</ul>

<p>🔗 GitHub Repository: <a href="https://github.com/leobip/python-custom-tools.git">python-custom-tools</a></p>]]></content><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><category term="Layout" /><category term="python" /><category term="help-tools" /><category term="edge case" /><summary type="html"><![CDATA[]]></summary></entry><entry><title type="html">🔍 SonarQube / SonarLint - Install, Config &amp;amp; Analysis</title><link href="http://localhost:4000/sonarqube/static%20analysis/tools/local-env-sonarqube/" rel="alternate" type="text/html" title="🔍 SonarQube / SonarLint - Install, Config &amp;amp; Analysis" /><published>2024-10-20T21:55:15+02:00</published><updated>2024-10-20T21:55:15+02:00</updated><id>http://localhost:4000/sonarqube/static%20analysis/tools/local-env-sonarqube</id><content type="html" xml:base="http://localhost:4000/sonarqube/static%20analysis/tools/local-env-sonarqube/"><![CDATA[<p>In this article, we will explore SonarQube and SonarLint, key tools for improving code quality. SonarQube acts as a central server for static code analysis, while SonarLint provides real-time feedback in the development environment. Additionally, we will see how to integrate them to maximize their effectiveness.</p>

<hr />

<figure style="display: flex; flex-direction: column; align-items: center;">
  <img src="/assets/images/2025-03-20-sonarqube-share.png" style="max-width:100%; height:auto;" />
  <figcaption style="margin-top: 0.5em; font-style: italic;">
  </figcaption>
</figure>

<h1 id="-sonarqube--sonarlint"><img src="/assets/images/2025-03-20-sonarqube-intensifies.gif" alt="SonarQube" width="40" style="vertical-align: middle;" /> SonarQube &amp; SonarLint</h1>

<h3 id="repository-reference">Repository Reference</h3>

<p>All the configuration files, including the <code class="language-plaintext highlighter-rouge">docker-compose.yaml</code> used in this article, are available in our repository:</p>

<p>👉 <a href="https://github.com/leobip/local-dev-env">local-dev-env Repository</a></p>

<p>This repository is intended to become the central place for our <strong>local development environment setup</strong>, where we will keep adding tools such as:</p>

<ul>
  <li><strong>SonarQube</strong> – Static code analysis (this article).</li>
  <li><strong>GitHub Actions Pipelines</strong> – CI/CD workflows.</li>
  <li><strong>ArgoCD</strong> – GitOps-based application deployment.</li>
  <li><strong>Monitoring stack</strong> – Observability for apps.</li>
  <li>And more developer tools…</li>
</ul>

<p>Each tool will have its <strong>own dedicated article</strong> with installation details, and the <strong>central article</strong> <code class="language-plaintext highlighter-rouge">Local Dev Environment</code> will explain how they all integrate together into a complete workflow.</p>

<h3 id="what-is-sonarqube">What is SonarQube?</h3>

<p><a href="https://www.sonarqube.org/">SonarQube</a> is a powerful static code analysis tool that helps developers identify bugs, security vulnerabilities, and code smells in their projects. It provides detailed insights to improve code quality and maintainability.</p>

<p>SonarQube is available in different editions:</p>

<ul>
  <li><strong>Community Edition</strong> (Free) – Open-source version with essential static analysis features.</li>
  <li><strong>Developer Edition</strong> – Adds advanced language support and branch analysis.</li>
  <li><strong>Enterprise Edition</strong> – Includes portfolio management and governance features.</li>
  <li><strong>Data Center Edition</strong> – High availability and scalability for large teams.</li>
</ul>

<p>For this guide, we will use the <strong>Community Edition</strong>.</p>

<h3 id="what-is-sonarlint">What is SonarLint?</h3>

<p><a href="https://www.sonarlint.org/">SonarLint</a> is an IDE plugin that provides real-time linting and code analysis. It helps developers catch issues early in the development process, ensuring consistent and high-quality code. It can be confiugured to work alone or with connection to SonarQube profiles, It functions as an extension of SonarQube when connected to the server.</p>

<h4 id="connection-between-sonarlint-and-sonarqube">Connection between SonarLint and SonarQube</h4>

<ul>
  <li>SonarLint can operate in two modes:
    <ul>
      <li>Standalone mode: Works independently in the IDE.</li>
      <li>Connected mode: Synchronizes with a SonarQube server to share rules and configurations.</li>
    </ul>
  </li>
  <li>To connect SonarLint with SonarQube:
    <ul>
      <li>Ensure that SonarQube is running.</li>
      <li>Install the SonarLint plugin in your IDE.</li>
      <li>Add the SonarQube URL in the SonarLint configuration.</li>
      <li>Authenticate with a SonarQube token.</li>
    </ul>
  </li>
</ul>

<hr />

<h3 id="database-support-in-sonarqube">Database Support in SonarQube</h3>

<h3 id="embedded-database-h2">Embedded Database (H2)</h3>

<p>By default, SonarQube <strong>Community Edition</strong> comes with an embedded <strong>H2 database</strong>. However, this database is only intended for <strong>evaluation and personal/local usage</strong>, as it is <strong>not recommended for production</strong> due to size &amp; data scalability limitations.</p>

<h3 id="supported-external-databases">Supported External Databases</h3>

<p>For a <strong>stable and production-ready</strong> deployment, SonarQube supports the following databases</p>

<ul>
  <li><strong>PostgreSQL</strong> (Recommended)</li>
  <li><strong>Microsoft SQL Server</strong></li>
  <li><strong>Oracle Database</strong></li>
</ul>

<h4 id="sonarqube-database-configuration-guides">SonarQube Database Configuration Guides</h4>

<ul>
  <li><a href="https://docs.sonarsource.com/sonarqube-server/latest/setup-and-upgrade/install-the-server/installing-the-database/">SonarQube Database Configuration Guide</a></li>
</ul>

<h2 id="installing-sonarqube-locally">Installing SonarQube Locally</h2>

<ul>
  <li>
    <p>Prerequisite:
Before setting up SonarQube, ensure that Docker &amp; docker-compose is installed on your machine. You can find the complete installation guide on the official Docker website, Docker Installation Guide:  https://docs.docker.com/engine/install/</p>
  </li>
  <li>
    <p>SonarQube Installation</p>
  </li>
</ul>

<p>To deploy SonarQube locally, we will use Docker Compose. This approach allows for future integration of additional tools and services within the local development environment. Using Docker Compose simplifies service configuration and management through a docker-compose.yaml file located in the project’s root directory.</p>

<p>Docker significantly simplifies the process of running SonarQube without requiring complex manual configurations.
For reference, the SonarQube page on Docker Hub (https://hub.docker.com/_/sonarqube)  provides links to repositories with example Dockerfile and docker-compose.yaml configurations, and instructions to install and run SonarQube with simplest command like:</p>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="s">docker run --name sonarqube-custom -p 9000:9000 sonarqube:community</span>
</code></pre></div></div>

<p>You can then browse to http://localhost:9000 or http://host-ip:9000 in your web browser to access the web interface.</p>

<h3 id="bonus-helm---installation-with-postgresql-included">Bonus: <strong>HELM</strong> - Installation with PostgreSQL Included</h3>

<p>For Kubernetes users, SonarQube can be installed using Helm with a <strong>PostgreSQL database included</strong>. Check out the official Helm package:  (here you can find different versions at Artifact Hub)
🔗 <a href="https://artifacthub.io/packages/helm/sonarqube/sonarqube">SonarQube Helm Chart</a></p>

<h3 id="folder-structure">Folder Structure</h3>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>local-dev-environment/
│
├── sonarqube/                  <span class="c"># SonarQube setup</span>
│   ├── conf/                   <span class="c"># Configuration files</span>
│   ├── data/                   <span class="c"># Data storage</span>
│   ├── logs/                   <span class="c"># Log files</span>
│   ├── extensions/             <span class="c"># Plugins and extensions</span>
│
├── docker-compose.yaml         <span class="c"># Docker Compose for multiple services</span>
...
</code></pre></div></div>

<ul>
  <li>docker-compose.yaml (at project root)</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="na">services</span><span class="pi">:</span>
  <span class="na">sonarqube</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">sonarqube:community</span> <span class="c1"># We are using the latest community version, it could also be the lts-community -(Long Term Support)</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">unless-stopped</span>  <span class="c1"># 🔄 Automatically restarts after a system reboot</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">sonar_db</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">SONAR_JDBC_URL</span><span class="pi">:</span> <span class="s">jdbc:postgresql://sonar_db:5432/sonar</span>
      <span class="na">SONAR_JDBC_USERNAME</span><span class="pi">:</span> <span class="s">sonar</span>
      <span class="na">SONAR_JDBC_PASSWORD</span><span class="pi">:</span> <span class="s">sonar</span>
    <span class="na">ports</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s2">"</span><span class="s">9001:9000"</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">sonarqube_conf:/opt/sonarqube/conf</span>
      <span class="pi">-</span> <span class="s">sonarqube_data:/opt/sonarqube/data</span>
      <span class="pi">-</span> <span class="s">sonarqube_extensions:/opt/sonarqube/extensions</span>
      <span class="pi">-</span> <span class="s">sonarqube_logs:/opt/sonarqube/logs</span>
      <span class="pi">-</span> <span class="s">sonarqube_temp:/opt/sonarqube/temp</span>

  <span class="na">sonar_db</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">postgres:13</span>
    <span class="na">restart</span><span class="pi">:</span> <span class="s">unless-stopped</span>  <span class="c1"># 🔄 Automatically restarts after a system reboot</span>
    <span class="na">environment</span><span class="pi">:</span>
      <span class="na">POSTGRES_USER</span><span class="pi">:</span> <span class="s">sonar</span>
      <span class="na">POSTGRES_PASSWORD</span><span class="pi">:</span> <span class="s">sonar</span>
      <span class="na">POSTGRES_DB</span><span class="pi">:</span> <span class="s">sonar</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">sonar_db:/var/lib/postgresql</span>
      <span class="pi">-</span> <span class="s">sonar_db_data:/var/lib/postgresql/data</span>

<span class="na">volumes</span><span class="pi">:</span>
  <span class="na">sonarqube_conf</span><span class="pi">:</span>
  <span class="na">sonarqube_data</span><span class="pi">:</span>
  <span class="na">sonarqube_extensions</span><span class="pi">:</span>
  <span class="na">sonarqube_logs</span><span class="pi">:</span>
  <span class="na">sonarqube_temp</span><span class="pi">:</span>
  <span class="na">sonar_db</span><span class="pi">:</span>
  <span class="na">sonar_db_data</span><span class="pi">:</span>

</code></pre></div></div>

<h3 id="automatic-backup-of-the-sonarqube-database-optional">Automatic Backup of the SonarQube Database (Optional)</h3>

<p>Even though we configured restart: unless-stopped, ensuring that data persists after a reboot, in our local environment, it’s good practice to have a backup strategy. Below is a solution using a backup service.</p>

<h4 id="manual-db-backup">Manual DB Backup</h4>

<ul>
  <li>To back up the PostgreSQL database:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">exec</span> <span class="nt">-t</span> postgres pg_dumpall <span class="nt">-c</span> <span class="nt">-U</span> sonar <span class="o">&gt;</span> backup.sql
</code></pre></div></div>

<ul>
  <li>To restore:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker <span class="nb">exec</span> <span class="nt">-i</span> postgres psql <span class="nt">-U</span> sonar <span class="nt">-d</span> sonarqube &lt; backup.sql
</code></pre></div></div>

<h4 id="adding-a-backup-service">Adding a Backup Service</h4>

<ul>
  <li>Add this code to the docker-compose.yaml</li>
</ul>

<div class="language-yaml highlighter-rouge"><div class="highlight"><pre class="highlight"><code>  <span class="na">sonar_backup</span><span class="pi">:</span>
    <span class="na">image</span><span class="pi">:</span> <span class="s">postgres:13</span>
    <span class="na">depends_on</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">sonar_db</span>
    <span class="na">volumes</span><span class="pi">:</span>
      <span class="pi">-</span> <span class="s">sonarqube_data:/opt/sonarqube/data</span>
    <span class="na">entrypoint</span><span class="pi">:</span> <span class="pi">[</span><span class="s2">"</span><span class="s">/bin/sh"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">-c"</span><span class="pi">,</span> <span class="s2">"</span><span class="s">while</span><span class="nv"> </span><span class="s">true;</span><span class="nv"> </span><span class="s">do</span><span class="nv"> </span><span class="s">/opt/sonarqube/data/backup_db.sh;</span><span class="nv"> </span><span class="s">sleep</span><span class="nv"> </span><span class="s">86400;</span><span class="nv"> </span><span class="s">done"</span><span class="pi">]</span>
</code></pre></div></div>

<ul>
  <li>Backup Script</li>
</ul>

<p>Create the following script inside sonarqube/data/backup_db.sh:</p>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c">#!/bin/bash</span>

<span class="c"># Configuration</span>
<span class="nv">BACKUP_DIR</span><span class="o">=</span><span class="s2">"/opt/sonarqube/data/backups"</span>
<span class="nv">TIMESTAMP</span><span class="o">=</span><span class="si">$(</span><span class="nb">date</span> +<span class="s2">"%Y-%m-%d_%H-%M-%S"</span><span class="si">)</span>
<span class="nv">BACKUP_FILE</span><span class="o">=</span><span class="s2">"</span><span class="nv">$BACKUP_DIR</span><span class="s2">/sonarqube_db_</span><span class="nv">$TIMESTAMP</span><span class="s2">.sql"</span>

<span class="c"># Create backup directory if it does not exist</span>
<span class="nb">mkdir</span> <span class="nt">-p</span> <span class="nv">$BACKUP_DIR</span>

<span class="c"># Perform PostgreSQL backup</span>
<span class="nv">PGPASSWORD</span><span class="o">=</span><span class="s2">"sonar"</span> pg_dump <span class="nt">-h</span> sonar_db <span class="nt">-U</span> sonar <span class="nt">-d</span> sonar <span class="o">&gt;</span> <span class="nv">$BACKUP_FILE</span>

<span class="c"># Clean up old backups (optional, keep only the last 5 backups)</span>
<span class="nb">ls</span> <span class="nt">-tp</span> <span class="nv">$BACKUP_DIR</span> | <span class="nb">grep</span> <span class="nt">-v</span> <span class="s1">'/$'</span> | <span class="nb">tail</span> <span class="nt">-n</span> +6 | xargs <span class="nt">-I</span> <span class="o">{}</span> <span class="nb">rm</span> <span class="nt">--</span> <span class="s2">"</span><span class="nv">$BACKUP_DIR</span><span class="s2">/{}"</span>

<span class="nb">echo</span> <span class="s2">"Backup completed: </span><span class="nv">$BACKUP_FILE</span><span class="s2">"</span>
</code></pre></div></div>

<ul>
  <li>Grant Execution Permission</li>
  <li>Run the following command to make the script executable:</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="nb">chmod</span> +x sonarqube/data/backup_db.sh
</code></pre></div></div>

<h3 id="conclusion">Conclusion</h3>

<ul>
  <li>SonarQube and PostgreSQL are configured with persistent storage.</li>
  <li>Containers automatically restart unless manually stopped.</li>
  <li>A backup service is set up to create database backups automatically.</li>
</ul>

<p>This setup ensures a robust SonarQube environment for local development. 🚀</p>

<h3 id="running-sonarqube">Running SonarQube</h3>

<p>Once the files are in place, follow these steps to start SonarQube:</p>

<ul>
  <li>Build the SonarQube image</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose build

</code></pre></div></div>

<ul>
  <li>Start the SonarQube container</li>
</ul>

<div class="language-bash highlighter-rouge"><div class="highlight"><pre class="highlight"><code>docker-compose up <span class="nt">-d</span>

</code></pre></div></div>

<p><img src="/assets/images/2025-03-20-sonarqube-docker-compose-creation.jpg" alt="compose-creation" /></p>

<ul>
  <li>Access SonarQube UI
    <ul>
      <li>Open http://localhost:9001 in your browser.</li>
      <li><img src="/assets/images/2025-03-20-sonar-login.jpg" alt="sonar-login" /></li>
    </ul>
  </li>
  <li>Login Credentials
    <ul>
      <li>Username: admin</li>
      <li>Password: admin</li>
    </ul>
  </li>
</ul>

<h2 id="installing-and-configuring-sonarqube-for-ide-fromerly-sonarlint">Installing and Configuring SonarQube for IDE (fromerly SonarLint)</h2>

<h3 id="installation">Installation</h3>

<h4 id="to-install-sonarlint-in-your-ide">To install SonarLint in your IDE</h4>

<ul>
  <li>VS Code: Install the “SonarLint” extension from the Extensions Marketplace</li>
  <li>IntelliJ IDEA: Install the “SonarLint” plugin from the Plugins Marketplace.</li>
  <li>Eclipse: Install the “SonarLint” plugin from the Eclipse Marketplace.</li>
</ul>

<p>Vs-Code Example</p>

<ul>
  <li><img src="/assets/images/2025-03-20-sonarlint-install1.jpg" alt="sonar-lint-vscode" /></li>
</ul>

<h5 id="using-sonarlint-in-standalone-mode">Using SonarLint in Standalone Mode</h5>

<p>SonarLint can work independently without connecting to a SonarQube server. In this mode, it provides static analysis using its built-in rule set.</p>

<p>For example, after installing SonarLint in VS Code:</p>

<ul>
  <li>Open a project.
    <ul>
      <li>SonarLint will automatically scan the files for issues.</li>
      <li>Hover over a warning to view explanations and possible fixes.</li>
    </ul>
  </li>
</ul>

<p>This is useful when you want quick feedback without setting up a full SonarQube instance.</p>

<ul>
  <li><img src="/assets/images/2025-03-20-sonarlint-find.png" alt="sonar-lint-find" /></li>
</ul>

<h5 id="configuration-in-connected-mode">Configuration in Connected Mode</h5>

<p>To connect SonarLint to SonarQube:</p>

<p>Open the SonarLint settings in your IDE.</p>

<p>Select “Connect to SonarQube or SonarCloud.”</p>

<p><img src="/assets/images/2025-03-20-sonarqube-ide-config1.jpg" alt="sonarqube-config-1" /></p>

<p>Enter the SonarQube server URL (e.g., http://localhost:9000).</p>

<p><img src="/assets/images/2025-03-20-sonarqube-ide-config2.jpg" alt="sonarqube-config2" /></p>

<p>Authenticate using a SonarQube token. (Or allow access from your Sonarqube instance)</p>

<p><img src="/assets/images/2025-03-20-sonarqube-ide-config3.jpg" alt="sonarqube-config3" /></p>

<hr />

<p><img src="/assets/images/2025-03-20-sonarqube-ide-config4.jpg" alt="sonarqube-config4" /></p>

<p>Select the project to synchronize the analysis rules.</p>

<p>Example of SonarLint in Action</p>

<p>Open a code file in your IDE.</p>

<p>If there are issues, SonarLint will highlight them with warnings and suggestions.</p>

<p>Hover over an issue to see details and possible fixes.</p>

<p>If connected to SonarQube, the rules from the server will be applied in real-time.</p>

<p><strong><em>With this setup, you have a functional SonarQube environment with persistence and an external database. Additionally, SonarLint enhances your development experience by providing real-time feedback. Now it’s time to analyze your code!</em></strong></p>

<h2 id="next-steps">Next Steps</h2>

<p>In this article, we focused on installing and configuring <strong>SonarQube</strong> with Docker Compose.<br />
This is part of a broader series about building a <strong>local development &amp; testing environment</strong>.</p>

<p>In the following articles, we will integrate additional tools such as <strong>GitHub Actions pipelines, ArgoCD, and monitoring solutions</strong>.<br />
When we introduce <strong>ArgoCD</strong>, we will also show how to migrate SonarQube from Docker Compose to Kubernetes and manage it through GitOps.</p>

<p>Stay tuned — our development environment will keep evolving step by step! 🚀</p>]]></content><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><category term="Sonarqube" /><category term="static analysis" /><category term="tools" /><category term="edge case" /><summary type="html"><![CDATA[In this article, we will explore SonarQube and SonarLint, key tools for improving code quality. SonarQube acts as a central server for static code analysis, while SonarLint provides real-time feedback in the development environment. Additionally, we will see how to integrate them to maximize their effectiveness.]]></summary></entry><entry><title type="html">Post Init</title><link href="http://localhost:4000/post-init/" rel="alternate" type="text/html" title="Post Init" /><published>2024-08-27T00:00:00+02:00</published><updated>2024-08-27T00:00:00+02:00</updated><id>http://localhost:4000/post-init</id><content type="html" xml:base="http://localhost:4000/post-init/"><![CDATA[<h1 id="hola--este-es-mi-primer-post-en-jekyll-con-el-tema-minimal-mistakes">Hola 👋, este es mi <strong>primer post</strong> en Jekyll con el tema <em>Minimal Mistakes</em></h1>

<p>Estoy probando cómo se ve el <strong>banner global</strong> y cómo se muestra en los posts.</p>]]></content><author><name>Leoncio López</name><email>leobip27@gmail.com</email></author><summary type="html"><![CDATA[Hola 👋, este es mi primer post en Jekyll con el tema Minimal Mistakes]]></summary></entry></feed>